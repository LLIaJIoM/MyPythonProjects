from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
import os
import time
import uuid
import json
from datetime import datetime

app = Flask(__name__)
CORS(app)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è IO Intelligence API
IO_API_BASE_URL = "https://api.intelligence.io.solutions/api/v1"
IO_API_KEY = "io-v2-eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJvd25lciI6IjY3YzM5OGE5LTZkNzYtNDMyZS1iYTlhLTY5ODZiODVjMmRkOCIsImV4cCI6NDkwNjQ4MTUwOX0.m0CayY7WgNNksnxAj-QAhsEYUEJNKbpujJoSm7sFwEwFxOeCNrrQx3jGLAh-vCwKd7wAvvDvFg3MnNjj8FIEdg"

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
last_response = ""
request_count = 0
error_count = 0

# –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è API –∑–∞–ø—Ä–æ—Å–æ–≤
def get_headers():
    return {
        "accept": "application/json",
        "Authorization": f"Bearer {IO_API_KEY}",
        "Content-Type": "application/json"
    }

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–ø–æ–ª—É—á–∞–µ–º –∏–∑ API)
AVAILABLE_MODELS = {}

def fetch_models():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ IO Intelligence API"""
    global AVAILABLE_MODELS
    try:
        response = requests.get(f"{IO_API_BASE_URL}/models", headers=get_headers())
        if response.status_code == 200:
            data = response.json()
            models = {}
            for model in data.get('data', []):
                model_id = model.get('id', '')
                if model_id:
                    models[model_id] = {
                        "id": model_id,
                        "object": "model",
                        "created": model.get('created', int(time.time())),
                        "owned_by": model.get('owned_by', 'io-intelligence'),
                        "permission": model.get('permission', [])
                    }
            AVAILABLE_MODELS = models
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –∏–∑ IO Intelligence API")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {response.status_code}")
            # Fallback –º–æ–¥–µ–ª–∏
            AVAILABLE_MODELS = {
                "deepseek-ai/DeepSeek-R1": {
                    "id": "deepseek-ai/DeepSeek-R1",
                    "object": "model",
                    "created": int(time.time()),
                    "owned_by": "io-intelligence"
                }
            }
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ IO Intelligence API: {e}")
        # Fallback –º–æ–¥–µ–ª–∏
        AVAILABLE_MODELS = {
            "deepseek-ai/DeepSeek-R1": {
                "id": "deepseek-ai/DeepSeek-R1",
                "object": "model",
                "created": int(time.time()),
                "owned_by": "io-intelligence"
            }
        }

@app.route('/v1/models', methods=['GET'])
def list_models():
    """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    models = []
    for model_id, model_data in AVAILABLE_MODELS.items():
        models.append({
            "id": model_id,
            "object": "model",
            "created": model_data.get('created', int(time.time())),
            "owned_by": model_data.get('owned_by', 'io-intelligence'),
            "permission": model_data.get('permission', [{
                "id": f"modelperm-{uuid.uuid4().hex[:24]}",
                "object": "model_permission",
                "created": int(time.time()),
                "allow_create_engine": False,
                "allow_sampling": True,
                "allow_logprobs": True,
                "allow_search_indices": False,
                "allow_view": True,
                "allow_fine_tuning": False,
                "organization": "*",
                "group": None,
                "is_blocking": False
            }]),
            "root": None,
            "parent": None,
            "max_model_len": None
        })
    
    return jsonify({
        "object": "list",
        "data": models
    })

@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    """–û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–∞—Ç-–∫–æ–º–ø–ª–µ—Ç–æ–≤"""
    global last_response, request_count, error_count
    
    request_count += 1
    
    try:
        data = request.get_json()
        messages = data.get('messages', [])
        model = data.get('model', 'deepseek-ai/DeepSeek-R1')
        temperature = data.get('temperature', 0.7)
        max_tokens = data.get('max_tokens', 1000)
        stream = data.get('stream', False)
        
        if not messages:
            return jsonify({"error": "No messages provided"}), 400
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ IO Intelligence API
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream
        }
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ IO Intelligence API
        response = requests.post(
            f"{IO_API_BASE_URL}/chat/completions",
            json=payload,
            headers=get_headers()
        )
        
        if response.status_code == 200:
            data = response.json()
            last_response = data.get('choices', [{}])[0].get('message', {}).get('content', '')
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ
            return jsonify(data)
        else:
            error_count += 1
            return jsonify({"error": f"IO Intelligence API error: {response.status_code}", "details": response.text}), response.status_code
        
    except Exception as e:
        error_count += 1
        return jsonify({"error": str(e)}), 500

@app.route('/v1/completions', methods=['POST'])
def completions():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∫–æ–º–ø–ª–µ—Ç–æ–≤ (legacy)"""
    global request_count, error_count
    
    request_count += 1
    
    try:
        data = request.get_json()
        prompt = data.get('prompt', '')
        model = data.get('model', 'deepseek-ai/DeepSeek-R1')
        temperature = data.get('temperature', 0.7)
        max_tokens = data.get('max_tokens', 1000)
        
        if not prompt:
            return jsonify({"error": "No prompt provided"}), 400
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ IO Intelligence API
        payload = {
            "model": model,
            "prompt": prompt,
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ IO Intelligence API
        response = requests.post(
            f"{IO_API_BASE_URL}/completions",
            json=payload,
            headers=get_headers()
        )
        
        if response.status_code == 200:
            data = response.json()
            return jsonify(data)
        else:
            error_count += 1
            return jsonify({"error": f"IO Intelligence API error: {response.status_code}", "details": response.text}), response.status_code
        
    except Exception as e:
        error_count += 1
        return jsonify({"error": str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "last_response": last_response[:100] + "..." if len(last_response) > 100 else last_response,
        "stats": {
            "total_requests": request_count,
            "error_count": error_count,
            "success_rate": ((request_count - error_count) / request_count * 100) if request_count > 0 else 100
        },
        "io_api_status": "connected" if AVAILABLE_MODELS else "disconnected"
    })

@app.route('/v1/models/<model_id>', methods=['GET'])
def get_model(model_id):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    if model_id not in AVAILABLE_MODELS:
        return jsonify({"error": "Model not found"}), 404
    
    model_data = AVAILABLE_MODELS[model_id]
    return jsonify({
        "id": model_id,
        "object": "model",
        "created": model_data.get('created', int(time.time())),
        "owned_by": model_data.get('owned_by', 'io-intelligence'),
        "permission": model_data.get('permission', [{
            "id": f"modelperm-{uuid.uuid4().hex[:24]}",
            "object": "model_permission",
            "created": int(time.time()),
            "allow_create_engine": False,
            "allow_sampling": True,
            "allow_logprobs": True,
            "allow_search_indices": False,
            "allow_view": True,
            "allow_fine_tuning": False,
            "organization": "*",
            "group": None,
            "is_blocking": False
        }]),
        "root": None,
        "parent": None,
        "max_model_len": None
    })

@app.route('/', methods=['GET'])
def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± API"""
    return jsonify({
        "message": "IO Intelligence API Server",
        "version": "1.0.0",
        "endpoints": {
            "models": "/v1/models",
            "chat_completions": "/v1/chat/completions",
            "completions": "/v1/completions",
            "health": "/health"
        },
        "available_models": list(AVAILABLE_MODELS.keys()),
        "api_provider": "IO Intelligence"
    })

@app.route('/test-io-api', methods=['GET'])
def test_io_api():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ IO Intelligence API"""
    try:
        response = requests.get(f"{IO_API_BASE_URL}/models", headers=get_headers())
        if response.status_code == 200:
            data = response.json()
            return jsonify({
                "status": "connected",
                "models_count": len(data.get('data', [])),
                "models": [model.get('id') for model in data.get('data', [])]
            })
        else:
            return jsonify({
                "status": "error",
                "status_code": response.status_code,
                "error": response.text
            })
    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        })

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8888))
    print(f"üöÄ –ó–∞–ø—É—Å–∫ IO Intelligence API —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    fetch_models()
    
    print(f"üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {list(AVAILABLE_MODELS.keys())}")
    print(f"üîó API –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: http://localhost:{port}")
    print(f"üîó –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: http://localhost:{port}/test-io-api")
    
    app.run(host='0.0.0.0', port=port, debug=False) 